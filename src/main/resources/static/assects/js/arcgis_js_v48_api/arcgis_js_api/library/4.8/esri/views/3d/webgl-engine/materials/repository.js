// All material copyright ESRI, All Rights Reserved, unless otherwise specified.
// See https://js.arcgis.com/4.8/esri/copyright.txt for details.
//>>built
require({cache:{"url:esri/views/3d/webgl-engine/materials/internal/hud.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\r\n\r\n\x3csnippets\x3e\r\n\r\n\x3csnippet name\x3d"commonAttributesAndUniformsHUD"\x3e\x3c![CDATA[\r\n  attribute vec3 $position;\r\n  attribute vec3 $normal;\r\n  attribute vec4 $auxpos1;\r\n\r\n  uniform mat4 proj;\r\n\r\n  uniform mat4 view;\r\n  uniform mat4 viewNormal;\r\n\r\n  uniform mat4 model;\r\n  uniform mat4 modelNormal;\r\n\r\n  uniform vec4 viewport;\r\n\r\n  uniform vec3 camPos;\r\n\r\n  uniform float polygonOffset;\r\n  uniform float cameraGroundRelative;\r\n\r\n#ifdef VERTICAL_OFFSET\r\n\r\n  // [ screenLength, distanceFactor, minWorldLength, maxWorldLength ]\r\n  uniform vec4 verticalOffset;\r\n\r\n#endif\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n  // [ divisor, offset, minPixelSize, paddingPixels ]\r\n  uniform vec4 screenSizePerspectiveAlignment;\r\n\r\n#endif\r\n\r\n  uniform sampler2D hudVisibilityTexture;\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"projectPositionHUD"\x3e\x3c![CDATA[\r\n  $screenSizePerspective\r\n\r\n  // Corresponds to cos(10 deg), used to compare against dot product of two vectors\r\n  const float SMALL_OFFSET_ANGLE \x3d 0.984807753012208;\r\n\r\n  struct ProjectHUDAux {\r\n    vec3 posModel;\r\n    vec3 posView;\r\n    vec3 vnormal;\r\n\r\n    float distanceToCamera;\r\n    float absCosAngle;\r\n  };\r\n\r\n\r\n  /**\r\n   * Apply the simulated polygon offset for HUD objects that improves\r\n   * issues with Z-fighting.\r\n   *\r\n   * @param posView {vec3} (inout) the position in view space. Will be modified in place.\r\n   * @param pointGroundDistance {float} the distance from the point geometry to the ground surface.\r\n   * @param absCosAngle {float} the absolute cosine of the angle between the world-up at the point geometry\r\n   *   and the view direction.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Attributes:\r\n   *     - auxpos1: contains centerOffset and pointGroundDistance\r\n   *\r\n   *   Uniforms:\r\n   *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\r\n   *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\r\n   *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\r\n   *         reduced flickering.\r\n   *     - viewport: the viewport [x, y, width, height]\r\n   */\r\n  float applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {\r\n    float pointGroundSign \x3d sign(pointGroundDistance);\r\n\r\n    if (pointGroundSign \x3d\x3d 0.0) {\r\n      pointGroundSign \x3d 1.0;\r\n    }\r\n\r\n    // cameraGroundRelative is -1 if camera is below ground, 1 if above ground\r\n    // groundRelative is 1 if both camera and symbol are on the same side of the ground, -1 otherwise\r\n    float groundRelative \x3d cameraGroundRelative * pointGroundSign;\r\n\r\n    // view angle dependent part of polygon offset emulation\r\n    // we take the absolute value because the sign that is dropped is\r\n    // instead introduced using the ground-relative position of the symbol and the camera\r\n    if (polygonOffset \x3e .0) {\r\n      float cosAlpha \x3d clamp(absCosAngle, 0.01, 1.0);\r\n\r\n      float tanAlpha \x3d sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;\r\n      float factor \x3d (1.0 - tanAlpha / viewport[2]);\r\n\r\n      // same side of the terrain\r\n      if (groundRelative \x3e 0.0) {\r\n        posView *\x3d factor;\r\n      }\r\n      // opposite sides of the terrain\r\n      else {\r\n        posView /\x3d factor;\r\n      }\r\n    }\r\n\r\n    return groundRelative;\r\n  }\r\n\r\n  /**\r\n   * Project the 3d position of a HUD object from world space to clip space. In addition\r\n   * to standard model view projection, it also emulates a polygon offset to\r\n   * help with points above/below ground and icon flickering. The resulting location\r\n   * is the anchor of the HUD object, i.e. the position that is used also for testing\r\n   * visibility of the HUD object. Note that the returned projected position is not\r\n   * aligned to a pixel center or border, it is up to the caller to align if necessary.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Attributes:\r\n   *     - position: contains the point world position\r\n   *     - normal: contains the world normal pointing up at the point\r\n   *     - auxpos1: contains centerOffset and pointGroundDistance\r\n   *\r\n   *   Uniforms:\r\n   *     - model: the object -\x3e world transformation matrix\r\n   *     - modelNormal: the object -\x3e world normal transformation matrix (inv transp of model)\r\n   *     - view: the world -\x3e view transformation matrix\r\n   *     - viewNormal: the world -\x3e view normal transformation matrix (inv transp of view)\r\n   *     - proj: the view -\x3e clip projection matrix\r\n   *     - verticalOffset: a vec4 containing:\r\n   *         - the screen height of the vertical offset\r\n   *         - the screen height of the vertical offset as a fraction of camera distance.\r\n   *         - the minimum world size vertical offset.\r\n   *         - the maximum world size vertical offset.\r\n   *       This will do a screen sized offset of the point along its normal (used for line callouts)\r\n   *     - screenSizePerspectiveAlignment: a vec3 containing\r\n   *         - the view distance dependent divisor\r\n   *         - the view distance dependent offset\r\n   *         - the minimum pixel size\r\n   *         - the amount of padding in pixels around the region to be scaled (not used for alignment)\r\n   *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\r\n   *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\r\n   *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\r\n   *         reduced flickering.\r\n   *     - camPos: the position of the camera in world space\r\n   *     - viewport: the viewport [x, y, width, height]\r\n   */\r\n  vec4 projectPositionHUD(out ProjectHUDAux aux) {\r\n    // centerOffset is in view space and is used to implement world size offsetting\r\n    // of labels with respect to objects. It also pulls the label towards the viewer\r\n    // so that the label is visible in front of the object.\r\n    vec3 centerOffset \x3d $auxpos1.xyz;\r\n\r\n    // The pointGroundDistance is the distance of the geometry to the ground and is\r\n    // negative if the point is below the ground, or positive if the point is above\r\n    // ground.\r\n    float pointGroundDistance \x3d $auxpos1.w;\r\n\r\n    aux.posModel \x3d (model * vec4($position, 1.0)).xyz;\r\n    aux.posView \x3d (view * vec4(aux.posModel, 1.0)).xyz;\r\n    aux.vnormal \x3d (modelNormal * vec4($normal, 1.0)).xyz;\r\n\r\n    // Screen sized offset in world space, used for example for line callouts\r\n    // Note: keep this implementation in sync with the CPU implementation, see\r\n    //   - MaterialUtil.verticalOffsetAtDistance\r\n    //   - HUDMaterial.applyVerticalOffsetTransformation\r\n\r\n    aux.distanceToCamera \x3d length(aux.posView);\r\n\r\n    vec3 viewDirObjSpace \x3d normalize(camPos - aux.posModel);\r\n    float cosAngle \x3d dot(aux.vnormal, viewDirObjSpace);\r\n\r\n    aux.absCosAngle \x3d abs(cosAngle);\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n#if defined(VERTICAL_OFFSET) || defined(CENTER_OFFSET_UNITS_SCREEN)\r\n    vec4 perspectiveFactor \x3d screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);\r\n#endif\r\n\r\n#endif\r\n\r\n#ifdef VERTICAL_OFFSET\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n    float verticalOffsetScreenHeight \x3d applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);\r\n#else\r\n    float verticalOffsetScreenHeight \x3d verticalOffset.x;\r\n#endif\r\n\r\n    float worldOffset \x3d clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);\r\n    vec3 modelOffset \x3d aux.vnormal * worldOffset;\r\n\r\n    aux.posModel +\x3d modelOffset;\r\n\r\n    vec3 viewOffset \x3d (viewNormal * vec4(modelOffset, 1.0)).xyz;\r\n    aux.posView +\x3d viewOffset;\r\n\r\n    // Since we elevate the object, we need to take that into account\r\n    // in the distance to ground\r\n    pointGroundDistance +\x3d worldOffset;\r\n\r\n#endif\r\n\r\n    float groundRelative \x3d applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);\r\n\r\n#ifndef CENTER_OFFSET_UNITS_SCREEN\r\n    // Apply x/y in view space, but z in screen space (i.e. along posView direction)\r\n    aux.posView +\x3d vec3(centerOffset.x, centerOffset.y, 0);\r\n\r\n    // Same material all have same z !\x3d 0.0 condition so should not lead to\r\n    // branch fragmentation and will save a normalization if it\'s not needed\r\n    if (centerOffset.z !\x3d 0.0) {\r\n      aux.posView -\x3d normalize(aux.posView) * centerOffset.z;\r\n    }\r\n#endif\r\n\r\n    vec4 posProj \x3d proj * vec4(aux.posView, 1.0);\r\n\r\n#ifdef CENTER_OFFSET_UNITS_SCREEN\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n    float centerOffsetY \x3d applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);\r\n#else\r\n    float centerOffsetY \x3d centerOffset.y;\r\n#endif\r\n\r\n    posProj.xy +\x3d vec2(centerOffset.x, centerOffsetY) * 2.0 / viewport.zw * posProj.w;\r\n\r\n#endif\r\n\r\n    // constant part of polygon offset emulation\r\n    posProj.z -\x3d groundRelative * polygonOffset * posProj.w;\r\n\r\n    return posProj;\r\n  }\r\n\r\n  uniform float uRenderTransparentlyOccludedHUD;\r\n\r\n  /**\r\n   * Test for visibility of a HUD object.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Uniforms:\r\n   *     - hudVisibilityTexture: the texture that contains the visibility information\r\n   *     - markerColor: the special marker color that is used to write visibility information\r\n   *     - viewport: the viewport\r\n   */\r\n  bool testVisibilityHUD(vec4 posProj) {\r\n    // For occlusion testing, use the nearest pixel center to avoid\r\n    // subpixel filtering messing up the color we use to test for\r\n    vec4 posProjCenter \x3d alignToPixelCenter(posProj, viewport.zw);\r\n\r\n    vec4 occlusionPixel \x3d texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w);\r\n\r\n    // the red pixel here indicates that the occlusion pixel passed the depth test against solid geometry and was written\r\n    // the green pixel stores transparency of transparent geometry (1.0 -\x3e fully transparent)\r\n    // note that we also check against green \x3d\x3d 0.0, i.e. transparent geometry that has opaque parts\r\n\r\n    // thus we render visible pixels that are occluded by semi-transparent (but not fully transparent!) geometry here\r\n    if (uRenderTransparentlyOccludedHUD \x3e 0.5) {\r\n      // multiplying by uRenderTransparentlyOccludedHUD allows us to ignore the second condition if\r\n      // uRenderTransparentlyOccludedHUD \x3d 0.75\r\n      return occlusionPixel.r * occlusionPixel.g \x3e 0.0 \x26\x26 occlusionPixel.g * uRenderTransparentlyOccludedHUD \x3c 1.0;\r\n    }\r\n    // and visible pixels that are not occluded by semi-transparent geometry here\r\n    else {\r\n      return occlusionPixel.r * occlusionPixel.g \x3e 0.0 \x26\x26 occlusionPixel.g \x3d\x3d 1.0;\r\n    }\r\n\r\n    // return texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w).r \x3e 0.0;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3c/snippets\x3e\r\n',
"url:esri/views/3d/webgl-engine/materials/internal/util.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\r\n\r\n\x3csnippets\x3e\r\n\r\n\x3csnippet name\x3d"alignToPixelCenter"\x3e\x3c![CDATA[\r\n  vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {\r\n    // From clip space to (0 : 1), bias towards right pixel edge\r\n    vec2 xy \x3d vec2(.500123) + .5 * clipCoord.xy / clipCoord.w;\r\n\r\n    // Size of a pixel in range (0 : 1)\r\n    vec2 pixelSz \x3d vec2(1.0) / widthHeight;\r\n\r\n    // Round to nearest pixel center\r\n    vec2 ij \x3d (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;\r\n\r\n    // Convert back to clip space\r\n    vec2 result \x3d (ij * 2.0 - vec2(1.0)) * clipCoord.w;\r\n\r\n    return vec4(result, clipCoord.zw);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"alignToPixelOrigin"\x3e\x3c![CDATA[\r\n  vec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {\r\n    // From clip space to (0 : 1),\r\n    vec2 xy \x3d vec2(.5) + .5 * clipCoord.xy / clipCoord.w;\r\n\r\n    // Size of a pixel in range (0 : 1)\r\n    vec2 pixelSz \x3d vec2(1.0) / widthHeight;\r\n\r\n    // Round to nearest pixel border, (0 : 1)\r\n    vec2 ij \x3d floor((xy + .5 * pixelSz) * widthHeight) * pixelSz;\r\n\r\n    // Convert back to clip space\r\n    vec2 result \x3d (ij * 2.0 - vec2(1.0)) * clipCoord.w;\r\n\r\n    return vec4(result, clipCoord.zw);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"float2rgba"\x3e\x3c![CDATA[\r\n  // This is the maximum float value representable as 32bit fixed point,\r\n  // it is rgba2float(vec4(1)) inlined.\r\n  const float MAX_RGBA_FLOAT \x3d\r\n    255.0 / 256.0 +\r\n    255.0 / 256.0 / 256.0 +\r\n    255.0 / 256.0 / 256.0 / 256.0 +\r\n    255.0 / 256.0 / 256.0 / 256.0 / 256.0;\r\n\r\n  // Factors to convert to fixed point, i.e. factors (256^0, 256^1, 256^2, 256^3)\r\n  const vec4 fixedPointFactors \x3d vec4(1, 256, 256 * 256, 256 * 256 * 256);\r\n\r\n  vec4 float2rgba(const float value) {\r\n    // Make sure value is in the domain we can represent\r\n    float valueInValidDomain \x3d clamp(value, 0.0, MAX_RGBA_FLOAT);\r\n\r\n    // Decompose value in 32bit fixed point parts represented as\r\n    // uint8 rgba components. Decomposition uses the fractional part after multiplying\r\n    // by a power of 256 (this removes the bits that are represented in the previous\r\n    // component) and then converts the fractional part to 8bits.\r\n    vec4 fixedPointU8 \x3d floor(fract(valueInValidDomain * fixedPointFactors) * 256.0);\r\n\r\n    // Convert uint8 values (from 0 to 255) to floating point representation for\r\n    // the shader\r\n    const float toU8AsFloat \x3d 1.0 / 255.0;\r\n\r\n    return fixedPointU8 * toU8AsFloat;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"rgba2float"\x3e\x3c![CDATA[\r\n  // Factors to convert rgba back to float\r\n  const vec4 rgba2float_factors \x3d vec4(\r\n    255.0 / (256.0),\r\n    255.0 / (256.0 * 256.0),\r\n    255.0 / (256.0 * 256.0 * 256.0),\r\n    255.0 / (256.0 * 256.0 * 256.0 * 256.0)\r\n  );\r\n\r\n  float rgba2float(vec4 rgba) {\r\n    // Convert components from 0-\x3e1 back to 0-\x3e255 and then\r\n    // add the components together with their corresponding\r\n    // fixed point factors, i.e. (256^1, 256^2, 256^3, 256^4)\r\n    return dot(rgba, rgba2float_factors);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"calcFragDepth"\x3e\x3c![CDATA[\r\n  float calcFragDepth(const in float depth) {\r\n    //calc polygon offset\r\n    const float SLOPE_SCALE \x3d 2.0;\r\n    const float BIAS \x3d 2.0 * .000015259;    // 1 / (2^16 - 1)\r\n    float m \x3d max(abs(dFdx(depth)), abs(dFdy(depth)));\r\n    float result \x3d depth + SLOPE_SCALE * m + BIAS;\r\n    return clamp(result, .0, .999999);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"evalShadow"\x3e\x3c![CDATA[\r\n  $rgba2float\r\n\r\n  // "matrix" parameter used to have const qualifier as well, but IE11 couldn\'t deal with it at time of writing.\r\n  // once IE11 is fine with it, const should probably be re-introduced\r\n  float evalShadow(const in vec3 vpos, const in float depth, const in sampler2D depthTex, const int num, const in vec4 distance, in mat4 matrix[4], const in float halfPxSz) {\r\n    //choose correct cascade\r\n    int i \x3d depth \x3c distance[1] ? 0 : depth \x3c distance[2] ? 1 : depth \x3c distance[3] ? 2 : 3;\r\n\r\n    if (i \x3e\x3d num) return .0;\r\n\r\n    mat4 mat \x3d i \x3d\x3d 0 ? matrix[0] : i \x3d\x3d 1 ? matrix[1] : i \x3d\x3d 2 ? matrix[2] : matrix[3];\r\n\r\n    vec4 lv \x3d mat * vec4(vpos, 1.0);\r\n    lv.xy /\x3d lv.w;\r\n\r\n    //vertex completely outside? -\x3e no shadow\r\n    vec3 lvpos \x3d .5 * lv.xyz + vec3(.5);\r\n    if (lvpos.z \x3e\x3d 1.0) return .0;\r\n    if (lvpos.x \x3c .0 || lvpos.x \x3e 1.0 || lvpos.y \x3c .0 || lvpos.y \x3e 1.0) return .0;\r\n\r\n    //calc coord in cascade texture\r\n    vec2 uv \x3d vec2(float(i - 2 * (i / 2)) *.5, float(i / 2) * .5) + .5 * lvpos.xy;\r\n\r\n    float texSize \x3d .5 / halfPxSz;\r\n\r\n    //filter, offset by half pixels\r\n    vec2 st \x3d fract((vec2(halfPxSz) + uv) * texSize);\r\n\r\n    float s00 \x3d rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, -halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n    float s10 \x3d rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, -halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n    float s11 \x3d rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n    float s01 \x3d rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n\r\n    return mix(mix(s00, s10, st.x), mix(s01, s11, st.x), st.y);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\r\n\x3c!--\r\n  Scene Lighting Definitions:\r\n  \x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\r\n\r\n  defines:\r\n    - SH_ORDER: 1|2|3\r\n  input:\r\n    - normal: vec3\r\n    - albedo: vec3\r\n    - shadow: float\r\n    - ssao: float\r\n  return:\r\n    - color: vec3\r\n--\x3e\r\n\x3csnippet name\x3d"sceneLightingDefinitions"\x3e\x3c![CDATA[\r\n  $viewingMode\r\n\r\n  // main light\r\n  /////////////////////////////////////////\r\n  uniform vec3 lightingMainDirection;\r\n  uniform vec3 lightingMainIntensity;\r\n\r\n  // ambient lighting\r\n  /////////////////////////////////////////\r\n  #ifndef SH_ORDER\r\n    #define SH_ORDER 2\r\n  #endif\r\n\r\n  #if SH_ORDER \x3d\x3d 0\r\n    uniform vec3 lightingAmbientSH0;\r\n  #elif SH_ORDER \x3d\x3d 1\r\n    uniform vec4 lightingAmbientSH_R;\r\n    uniform vec4 lightingAmbientSH_G;\r\n    uniform vec4 lightingAmbientSH_B;\r\n  #elif SH_ORDER \x3d\x3d 2\r\n    uniform vec3 lightingAmbientSH0;\r\n    uniform vec4 lightingAmbientSH_R1;\r\n    uniform vec4 lightingAmbientSH_G1;\r\n    uniform vec4 lightingAmbientSH_B1;\r\n    uniform vec4 lightingAmbientSH_R2;\r\n    uniform vec4 lightingAmbientSH_G2;\r\n    uniform vec4 lightingAmbientSH_B2;\r\n  #endif\r\n\r\n  // special tweaking\r\n  //////////////////////////////////////////\r\n  uniform float lightingFixedFactor;\r\n  uniform float lightingGlobalFactor;\r\n\r\n  uniform float ambientBoostFactor;\r\n\r\n  // evaluation\r\n  //////////////////////////////////////////\r\n\r\n  vec3 evaluateSceneLighting(vec3 normal, vec3 albedo, float shadow, float ssao, vec3 additionalLight) {\r\n    // evaluate the main light\r\n    float dotVal \x3d mix(clamp(-dot(normal, lightingMainDirection), 0.0, 1.0), 1.0, lightingFixedFactor);\r\n    vec3 mainLight \x3d (1.0 - shadow) * lightingMainIntensity * dotVal;\r\n\r\n    // evaluate the sh ambient light\r\n    #if SH_ORDER \x3d\x3d 0\r\n      vec3 ambientLight \x3d 0.282095 * lightingAmbientSH0;\r\n    #elif SH_ORDER \x3d\x3d 1\r\n      vec4 sh0 \x3d vec4(\r\n        0.282095,\r\n        0.488603 * normal.x,\r\n        0.488603 * normal.z,\r\n        0.488603 * normal.y\r\n      );\r\n      vec3 ambientLight \x3d vec3(\r\n        dot(lightingAmbientSH_R, sh0),\r\n        dot(lightingAmbientSH_G, sh0),\r\n        dot(lightingAmbientSH_B, sh0)\r\n      );\r\n    #elif SH_ORDER \x3d\x3d 2\r\n      vec3 ambientLight \x3d 0.282095 * lightingAmbientSH0;\r\n\r\n      vec4 sh1 \x3d vec4(\r\n        0.488603 * normal.x,\r\n        0.488603 * normal.z,\r\n        0.488603 * normal.y,\r\n        1.092548 * normal.x * normal.y\r\n      );\r\n      vec4 sh2 \x3d vec4(\r\n        1.092548 * normal.y * normal.z,\r\n        0.315392 * (3.0 * normal.z * normal.z - 1.0),\r\n        1.092548 * normal.x * normal.z,\r\n        0.546274 * (normal.x * normal.x - normal.y * normal.y)\r\n      );\r\n      ambientLight +\x3d vec3(\r\n        dot(lightingAmbientSH_R1, sh1),\r\n        dot(lightingAmbientSH_G1, sh1),\r\n        dot(lightingAmbientSH_B1, sh1)\r\n      );\r\n      ambientLight +\x3d vec3(\r\n        dot(lightingAmbientSH_R2, sh2),\r\n        dot(lightingAmbientSH_G2, sh2),\r\n        dot(lightingAmbientSH_B2, sh2)\r\n      );\r\n    #endif\r\n    ambientLight *\x3d (1.0 - ssao);\r\n\r\n    // inverse gamma correction on the albedo color\r\n    float gamma \x3d 2.1;\r\n    vec3 albedoGammaC \x3d pow(albedo, vec3(gamma));\r\n\r\n    // physically correct BRDF normalizes by PI\r\n    const float PI \x3d 3.14159;\r\n    vec3 totalLight \x3d mainLight + ambientLight + additionalLight;\r\n    totalLight \x3d min(totalLight, vec3(PI, PI, PI));\r\n    vec3 outColor \x3d vec3((albedoGammaC / PI) * (totalLight));\r\n\r\n    // apply gamma correction to the computed color\r\n    outColor \x3d pow(outColor, vec3(1.0/gamma));\r\n\r\n    return outColor;\r\n  }\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"sceneLightingAdditionalLightGlobal"\x3e\x3c![CDATA[\r\n  vec3 sceneLightingAdditionalLightGlobal(vec3 worldPos, float ssao, out float additionalAmbientScale) {\r\n    // heuristic lighting model originally used in the terrain shading\r\n    // now used to generated additional ambient light\r\n\r\n#ifdef VIEWING_MODE_GLOBAL\r\n\r\n      float vndl \x3d -dot(normalize(worldPos), lightingMainDirection);\r\n\r\n#else\r\n\r\n      float vndl \x3d -dot(vec3(0,0,1), lightingMainDirection);\r\n\r\n#endif\r\n\r\n    additionalAmbientScale \x3d smoothstep(0.0, 1.0, clamp(vndl * 2.5, 0.0, 1.0));\r\n    return ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"normal2envTC"\x3e\x3c![CDATA[\r\n  vec2 normal2envTC(vec3 normal) {\r\n    float v \x3d .5 + .5 * asin(normal.y) * 0.63661977;\r\n    float u \x3d .5 - .5 * atan(normal.z, normal.x) * 0.31830988;\r\n    return vec2(u, v);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vertexShaderShowDepth"\x3e\x3c![CDATA[\r\n  $vsprecisionf\r\n\r\n  uniform mat4 proj;\r\n  attribute vec2 $position;\r\n  attribute vec2 $uv0;\r\n  varying vec2 vtc;\r\n\r\n  void main(void) {\r\n    gl_Position \x3d proj * vec4($position.x, $position.y, .0, 1.0);\r\n    vtc \x3d $uv0;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n  \x3csnippet name\x3d"fragmentShaderShowDepth"\x3e\x3c![CDATA[\r\n  $fsprecisionf\r\n\r\n  uniform sampler2D depthTex;\r\n  varying vec2 vtc;\r\n  $rgba2float\r\n  void main() {\r\n  // gl_FragColor \x3d vec4(vec3(texture2D(depthTex, vtc).a), 1.0);\r\n     gl_FragColor \x3d vec4(rgba2float(texture2D(depthTex, vtc)));\r\n  // gl_FragColor \x3d texture2D(depthTex, vtc);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vsUVQuad"\x3e\x3c![CDATA[\r\n  $vsprecisionf\r\n\r\n  attribute vec2 $position;\r\n  varying vec2 uv;\r\n\r\n  void main(void) {\r\n    gl_Position \x3d vec4($position.x, $position.y, .0, 1.0);\r\n    uv \x3d $position * .5 + vec2(.5);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"toScreenCoords"\x3e\x3c![CDATA[\r\n  vec4 toScreenCoords(vec3 vertex) {\r\n    vec4 vClipSpace \x3d proj * view * vec4((model * vec4(vertex, 1.0)).xyz, 1.0);\r\n    vClipSpace.xy *\x3d screenSize;\r\n    return vClipSpace/abs(vClipSpace.w);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vvUniforms"\x3e\x3c![CDATA[\r\n#if defined(VV_SIZE)\r\n  #define VV_CUSTOM_MODEL_MATRIX\r\n#endif\r\n\r\n#if defined(VV_SIZE)\r\n  uniform vec3 vvSizeMinSize;\r\n  uniform vec3 vvSizeMaxSize;\r\n  uniform vec3 vvSizeOffset;\r\n  uniform vec3 vvSizeFactor;\r\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\r\n  uniform vec3 vvSizeValue;\r\n#endif\r\n\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n  uniform mat3 vvSymbolRotation;\r\n#endif\r\n\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n  uniform vec3 vvSymbolAnchor;\r\n#endif\r\n\r\n#ifdef VV_COLOR\r\n  #define VV_COLOR_N 8\r\n  uniform float vvColorValues[VV_COLOR_N];\r\n  uniform vec4 vvColorColors[VV_COLOR_N];\r\n#endif\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vvFunctions"\x3e\x3c![CDATA[\r\n// Evaluation of size\r\n#if defined(VV_SIZE)\r\n  vec3 vvGetScale(vec4 featureAttribute) {\r\n    return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize);\r\n  }\r\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\r\n  vec3 vvGetScale(vec4 featureAttribute) {\r\n    return vvSizeValue;\r\n  }\r\n#endif\r\n\r\n// Applying the model matrix\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n  vec4 vvTransformPosition(vec3 position, vec4 featureAttribute) {\r\n    return vec4(vvSymbolRotation * (vvGetScale(featureAttribute) * (position + vvSymbolAnchor)), 1.0);\r\n  }\r\n\r\n  vec4 vvTransformNormal(vec3 normal, vec4 featureAttribute) {\r\n    // Normal transform is the inverse transpose of model transform\r\n    return vec4(vvSymbolRotation * normal / vvGetScale(featureAttribute), 1.0);\r\n  }\r\n#endif\r\n\r\n#ifdef VV_COLOR\r\n  vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\r\n    float value \x3d featureAttribute.y;\r\n    if (value \x3c\x3d values[0]) {\r\n      return colors[0];\r\n    }\r\n\r\n    for (int i \x3d 1; i \x3c VV_COLOR_N; ++i) {\r\n      if (values[i] \x3e\x3d value) {\r\n        float f \x3d (value - values[i-1]) / (values[i] - values[i-1]);\r\n        return mix(colors[i-1], colors[i], f);\r\n      }\r\n    }\r\n\r\n    return colors[VV_COLOR_N - 1];\r\n  }\r\n#endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"rgb2hsv"\x3e\x3c![CDATA[\r\nvec3 rgb2hsv(vec3 c)\r\n{\r\n  vec4 K \x3d vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\r\n  vec4 p \x3d mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\r\n  vec4 q \x3d mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\r\n\r\n  float d \x3d q.x - min(q.w, q.y);\r\n  float e \x3d 1.0e-10;\r\n  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);\r\n}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"hsv2rgb"\x3e\x3c![CDATA[\r\nvec3 hsv2rgb(vec3 c)\r\n{\r\n  vec4 K \x3d vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\r\n  vec3 p \x3d abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\r\n  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\r\n}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"colorMixMode"\x3e\x3c![CDATA[\r\n$rgb2hsv\r\n$hsv2rgb\r\n\r\n\r\n/*\r\n * The color mix modes are encoded in the symbol color as follows:\r\n *  - Fully transparent symbols are represented with alpha 0 for\r\n *    all color mix modes (except ignore).\r\n *  - color mix mode ignore is encoded as multiply with white\r\n *  - the other 3 color mix modes (tint, replace, multiply) are\r\n *    equally distributed on the remaining 255 alpha values, which\r\n *    gives us 85 possible alpha values\r\n *\r\n * alpha             0 : fully transparent\r\n * alpha in [  1 -  85]: tint\r\n * alpha in [ 86 - 170]: replace\r\n * alpha in [171 - 255]: multiply\r\n */\r\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\r\n  float symbolAlpha \x3d 0.0;\r\n\r\n  const float maxTint \x3d 85.0;\r\n  const float maxReplace \x3d 170.0;\r\n  const float scaleAlpha \x3d 3.0;\r\n\r\n  if (symbolColor.a \x3d\x3d 0.0) {\r\n    colorMixMode \x3d 1; // fully transparent -\x3e multiply\r\n    symbolAlpha \x3d 0.0;\r\n  }\r\n  else if (symbolColor.a \x3c\x3d maxTint) {\r\n    colorMixMode \x3d 0; // tint\r\n    symbolAlpha \x3d scaleAlpha * symbolColor.a;\r\n  }\r\n  else if (symbolColor.a \x3c\x3d maxReplace) {\r\n    colorMixMode \x3d 3; // replace\r\n    symbolAlpha \x3d scaleAlpha * (symbolColor.a - maxTint);\r\n  }\r\n  else {\r\n    colorMixMode \x3d 1;  // multiply\r\n    symbolAlpha \x3d scaleAlpha * (symbolColor.a - maxReplace);\r\n  }\r\n\r\n  return vec4(symbolColor.rgb, symbolAlpha);\r\n}\r\n\r\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\r\n\r\n  // workaround for artifacts in OSX using Intel Iris Pro\r\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\r\n  vec3 internalMixed \x3d internalColor * textureColor;\r\n  vec3 allMixed \x3d internalMixed * externalColor;\r\n\r\n  if (mode \x3d\x3d 1 /* multiply */) {\r\n    return allMixed;\r\n  }\r\n  else if (mode \x3d\x3d 2 /* ignore */ ) {\r\n    return internalMixed;\r\n  }\r\n  else if (mode \x3d\x3d 3 /* replace */ ) {\r\n    return externalColor;\r\n  }\r\n  else {\r\n    // tint (or something invalid)\r\n    vec3 hsvIn \x3d rgb2hsv(internalMixed);\r\n    vec3 hsvTint \x3d rgb2hsv(externalColor);\r\n    vec3 hsvOut \x3d vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\r\n    return hsv2rgb(hsvOut);\r\n  }\r\n}\r\n\r\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\r\n\r\n  // workaround for artifacts in OSX using Intel Iris Pro\r\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\r\n  float internalMixed \x3d internalOpacity * textureOpacity;\r\n  float allMixed \x3d internalMixed * externalOpacity;\r\n\r\n  if (mode \x3d\x3d 2 /* ignore */ ) {\r\n    return internalMixed;\r\n  }\r\n  else if (mode \x3d\x3d 3 /* replace */ ) {\r\n    return externalOpacity;\r\n  }\r\n  else {\r\n    // multiply or tint (or something invalid)\r\n    return allMixed;\r\n  }\r\n}\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"highlightWrite"\x3e\x3c![CDATA[\r\n  // the following uniforms are common to all highlight shaders:\r\n  // uniform sampler2D depthTex\r\n  // uniform vec4 highlightViewportPixelSz\r\n  float sceneDepth \x3d texture2D(depthTex, (gl_FragCoord.xy - highlightViewportPixelSz.xy) * highlightViewportPixelSz.zw).r;\r\n  if (gl_FragCoord.z \x3e sceneDepth + 5e-6) {\r\n    gl_FragColor \x3d vec4(1.0, 1.0, 0.0, 1.0);\r\n  }\r\n  else {\r\n    gl_FragColor \x3d vec4(1.0, 0.0, 1.0, 1.0);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"screenSizePerspective"\x3e\x3c![CDATA[\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n// Note that the implementation here should be kept in sync with the corresponding\r\n// CPU implementation (used for hitTest etc) in screenSizePerspectiveUtils.ts\r\n\r\n/**\r\n * Compute the screen size perspective lower bound from pre-computed screen\r\n * size perspective factors (or parameters, since both store the pixel lower\r\n * bound information in the same place). When computing the minimum size,\r\n * the padding (e.g. text halo) is scaled with the same factor as the\r\n * original size scales to reach the minimum size.\r\n *\r\n * {\r\n *    x: N/A\r\n *    y: N/A\r\n *    z: minPixelSize (abs),\r\n *    w: sizePaddingInPixels (abs)\r\n * }\r\n */\r\nfloat screenSizePerspectiveMinSize(float size, vec4 factor) {\r\n\r\n  // Original calculation:\r\n  //   padding \x3d 2 * factor.w\r\n  //   minSize \x3d factor.z\r\n  //\r\n  //   minSize + minSize / size * padding\r\n  //\r\n  // Incorporates padding (factor.w, e.g. text halo size) into the\r\n  // minimum bounds calculation, taking into account that padding\r\n  // would scale down proportionally to the size.\r\n  //\r\n  // Calculation below is the same, but avoids division by zero when\r\n  // size would be zero, without branching using step.\r\n  // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10683\r\n\r\n  // nonZeroSize is 1 if size \x3e 0, and 0 otherwise\r\n  float nonZeroSize \x3d 1.0 - step(size, 0.0);\r\n\r\n  return (\r\n    factor.z * (\r\n      1.0 +\r\n      nonZeroSize *                // Multiply by nzs ensures if size is 0, then we ignore\r\n                                   // proportionally scaled padding\r\n      2.0 * factor.w / (\r\n        size + (1.0 - nonZeroSize) // Adding 1 - nzs ensures we divide either by size, or by 1\r\n      )\r\n    )\r\n  );\r\n}\r\n\r\n/**\r\n * Computes the view angle dependent screen size perspective factor. The goal\r\n * of this factor is that:\r\n *\r\n *   1. There is no perspective when looking top-down\r\n *   2. There is a smooth and quick transition to full perspective when\r\n *      tilting.\r\n */\r\nfloat screenSizePerspectiveViewAngleDependentFactor(float absCosAngle) {\r\n  return absCosAngle * absCosAngle * absCosAngle;\r\n}\r\n\r\n/**\r\n * Precomputes a set of factors that can be used to apply screen size perspective\r\n * The factors are based on the viewing angle, distance to camera and the screen size\r\n * perspective parameters:\r\n * {\r\n *    x: distanceDivisor,\r\n *    y: distanceOffset,\r\n *    z: minPixelSize (abs),\r\n *    w: sizePaddingInPixels (abs)\r\n * }\r\n *\r\n * The result is a set of factors that can be used to apply the perspective:\r\n *\r\n * {\r\n *    x: distance based relative scale factor (0 -\x3e 1)\r\n *    y: view dependent scale factor\r\n *    z: minPixelSize (abs)\r\n *    w: sizePaddingInPixels (abs)\r\n * }\r\n */\r\nvec4 screenSizePerspectiveScaleFactor(float absCosAngle, float distanceToCamera, vec4 params) {\r\n  return vec4(min(params.x / (distanceToCamera - params.y), 1.0), screenSizePerspectiveViewAngleDependentFactor(absCosAngle), params.z, params.w);\r\n}\r\n\r\n/**\r\n * Applies screen size perspective factors to a single dimension size, given the viewing angle,\r\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\r\n * perspective parameters using screenSizePerspectiveScaleFactorFloat.\r\n *\r\n * Note that for single scale application, the screenSizePerspectiveScaleFloat can be used, which\r\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorFloat.\r\n */\r\n\r\nfloat applyScreenSizePerspectiveScaleFactorFloat(float size, vec4 factor) {\r\n  return max(mix(size * factor.x, size, factor.y), screenSizePerspectiveMinSize(size, factor));\r\n}\r\n\r\n/**\r\n * Applies screen size perspective parameters to a single dimension size, given the viewing angle,\r\n * distance to camera and perspective parameters\r\n * {\r\n *    x: distanceDivisor,\r\n *    y: distanceOffset,\r\n *    z: minPixelSize (abs),\r\n *    w: sizePaddingInPixels (abs)\r\n * }\r\n */\r\nfloat screenSizePerspectiveScaleFloat(float size, float absCosAngle, float distanceToCamera, vec4 params) {\r\n  return applyScreenSizePerspectiveScaleFactorFloat(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\r\n}\r\n\r\n/**\r\n * Applies screen size perspective factors to a vec2 size (width/height), given the viewing angle,\r\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\r\n * perspective parameters using screenSizePerspectiveScaleFactorVec2.\r\n *\r\n * Note that for single scale application, the screenSizePerspectiveScaleVec2 can be used, which\r\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorVec2.\r\n */\r\nvec2 applyScreenSizePerspectiveScaleFactorVec2(vec2 size, vec4 factor) {\r\n  return mix(size * clamp(factor.x, screenSizePerspectiveMinSize(size.y, factor) / size.y, 1.0), size, factor.y);\r\n}\r\n\r\n/**\r\n * Applies screen size perspective parameters to a vec2 size (width/height), given the viewing angle,\r\n * distance to camera and perspective parameters\r\n * {\r\n *    x: distanceDivisor,\r\n *    y: distanceOffset,\r\n *    z: minPixelSize (abs),\r\n *    w: sizePaddingInPixels (abs)\r\n * }\r\n */\r\nvec2 screenSizePerspectiveScaleVec2(vec2 size, float absCosAngle, float distanceToCamera, vec4 params) {\r\n  return applyScreenSizePerspectiveScaleFactorVec2(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\r\n}\r\n\r\n#endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"computeNormal"\x3e\x3c![CDATA[\r\n  #ifdef GROUND_NORMAL_SHADING\r\n    #ifdef VIEWING_MODE_GLOBAL\r\n      vec3 normal \x3d normalize(vpos + localOrigin);\r\n    #else\r\n      vec3 normal \x3d vec3(0,0,1);\r\n    #endif\r\n  #else\r\n    // compute normal\r\n    #ifdef DOUBLESIDED\r\n      vec3 normal \x3d dot(vnormal, viewDir)\x3e0.0 ? -vnormal : vnormal;\r\n    #elif defined(WINDINGORDERDOUBLESIDED)\r\n      vec3 normal \x3d gl_FrontFacing ? vnormal : -vnormal;\r\n    #else\r\n      vec3 normal \x3d vnormal;\r\n    #endif\r\n    normal \x3d normalize(normal);\r\n  #endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"decodeNormal"\x3e\x3c![CDATA[\r\nvec3 decodeNormal(vec2 f)\r\n{\r\n    float z \x3d 1.0 - abs(f.x) - abs(f.y);\r\n    return vec3(f + sign(f) * min(z, 0.0), z);\r\n}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3c/snippets\x3e\r\n'}});
define("require exports dojo/text!./internal/hud.xml dojo/text!./internal/util.xml ../lib/edgeRendering/EdgeView ./CheckerBoardMaterial ./ColorMaterial ./DefaultMaterial ./HUDMaterial ./LineCalloutMaterial ./MeasurementArrowMaterial ./RibbonLineMaterial ./internal/BlendLayers ./internal/SimpleGLMaterial ./internal/TexOnlyGLMaterial".split(" "),function(v,d,e,f,g,h,k,l,m,n,p,q,r,t,u){Object.defineProperty(d,"__esModule",{value:!0});d.initializeShaders=function(a,b,c){a._parse(f);a._parse(e);t.loadShaders(a,
b,c);u.loadShaders(a,b,c);l.loadShaders(a,b,c);m.loadShaders(a,b,c);n.loadShaders(a,b,c);q.loadShaders(a,b,c);r.loadShaders(a,b,c);k.loadShaders(a,b,c);p.loadShaders(a,b,c);g.EdgeView.loadShaders(a,b,c);h.loadShaders(a,b,c)}});